## Introduction

## The study of water quality in marine ecosystems is essential for understanding the processes that regulate biological productivity and the health of coastal environments. In particular, dissolved inorganic nutrients, such as nitrites, nitrates, and phosphates, play an essential role in nutrient cycling, as they constitute the basis of phytoplankton growth and marine trophic dynamics. Chlorophyll a concentration, meanwhile, is a widely used indicator for estimating phytoplankton biomass and assessing the level of primary productivity in an aquatic system. In the Mexican Caribbean, specifically on the coasts of Quintana Roo, growing pressure from tourism, urban development, and intensive human activities has raised concerns about the increased input of nutrients into the sea. This phenomenon can trigger eutrophication processes, changes in the structure of biological communities, and, in extreme cases, affect the health of coral reefs, ecosystems of great ecological and economic importance to the region. Therefore, the analysis of nitrites, nitrates, phosphates, and chlorophyll a in seawater is an indispensable tool for assessing trophic status, detecting potential alterations in environmental quality, and providing scientific information to support conservation strategies and sustainable management of Quintana Roo's marine resources (Hern√°ndez-Terrones et al., 2015; Herrera-Silveira et al., 2014 y Herrera-Silveira, 2005). The objective of this project was to estimate the relationship between nutrients (nitrites, nitrates, ammonium, phosphate, and chlorophyll a) on the coasts of Punta Canc√∫n to Tulum.
## Nutrients in water and their validation according to the EPA
## Nitrite (mg N-NO2-/L) = U.S. Environmental Protection Agency, 1979; NMX-AA-099-SCFI-2006
## Nitrate (mg N-NO3-/L) = Jenkins, D., and Medsken, L. 1964 and U.S. Environmental Protection Agency 1971 and 1975
## Ammonia (mg N-NH4+/L) = Solorzano, 1969 and Parsons et al., 1984
## Phosphates (mg PO4-3/L) = Henriksen, 1996 and U.S. Environmental Protection Agency, 1979
## Chlorophyll a (mg/m3) = Lorenz et al., 1967 and Aminot and Rey, 2000 

# Read the file into a DataFrame: df
def import_csv(file):
    # Read the file into a DataFrame: df
    import pandas as pd 
    return pd.read_csv(file)

# Path to the file to be imported
path = "C:\\\\Users\\\\DELL\\\\Desktop\\\\Curso_An√°lisis Estadistico_Phyton2025\\\\Curso_Analisis-estad-stico\\\\scritps_nuevo\\\\mi-proyecto\\\\Proyecto final\\\\Nutrientes_QuintanaRoo.csv"

# Import the file
Nutrientes_df = import_csv(path)

# Print variable names
print(Nutrientes_df.columns)
print(Nutrientes_df.info())


import matplotlib.pyplot as plt

# Plot a simple nutrient histogram 
#nitrites
Nitritos = Nutrientes_df["Nitritos_mg/L"]

plt.hist(Nitritos, bins=10)
plt.xlabel("Nitritos (mg/L)")
plt.ylabel("Probablity")
plt.show()

#nitrates
Nitratos = Nutrientes_df["Nitratos_mg/L"]

plt.hist(Nitratos, bins=10)
plt.xlabel("Nitritos (mg/L)")
plt.ylabel("Probablity")
plt.show()

#phosphates
Fosfatos = Nutrientes_df["Fosfatos_mg/L"]

plt.hist(Fosfatos, bins=10)
plt.xlabel("Fosfatos (mg/L)")
plt.ylabel("Probablity")
plt.show()

#Shapiro-Wilk Test 
from scipy.stats import shapiro

ta = Nutrientes_df['Nitratos_mg/L']

stat, p = shapiro(ta)
print(f'Estad√≠stico= {stat:.5f}, p-valor= {p:.5f}')
if p > 0.05:
    print("La distribuci√≥n es normal (no se rechaza H0)")
else:
    print("La distribuci√≥n NO es normal (se rechaza H0)")

#Estad√≠stico= 0.86910, p-valor= 0.01394
#La distribuci√≥n NO es normal (se rechaza H0)

# Kruskal-Wallis H-test for independent samples
# Import the file
Nutrientes_data = import_csv(path)
from scipy.stats import kruskal

def kruskal_wallis_test(*groups, alpha=0.05):
    """
    Performs the Kruskal-Wallis H-test for independent samples.
    Accepts multiple groups as arguments.
    Prints the H statistic, p-value, and interpretation.
    """
    result = kruskal(*groups)
    
    print(f"H statistic = {result.statistic}")
    print(f"p-value = {result.pvalue}")
    
    if result.pvalue < alpha:
        print("The difference between groups is statistically significant.")
    else:
        print("No statistically significant difference between groups.")

import scikit_posthocs as sp
# You need to install the scikit-posthocs package: conda install -c conda-forge scikit-posthocs

def dunn_posthoc(data, group_col, value_col, p_adjust='bonferroni'):
    """
    Runs Dunn's post-hoc test after Kruskal-Wallis.
    """
    result = sp.posthoc_dunn(data, val_col=value_col, group_col=group_col, p_adjust=p_adjust)
    print(result)
    return result

# Plot ta values for each area of the lagoon using seaborn
import seaborn as sns
import matplotlib.pyplot as plt

# Relationship of nutrients with temperature
sns.boxplot(x='Temp', y='Nitritos_mg/L', data=Nutrientes_data)
plt.xlabel('Nitrites (mg/L)')
plt.ylabel('Temperatura (¬∞)')
plt.title('Relationship of nutrients with temperature')
plt.show()

# Nitrates
sns.boxplot(x='Temp', y='Nitratos_mg/L', data=Nutrientes_data)
plt.xlabel('Nitrates (mg/L)')
plt.ylabel('Temperatura (¬∞)')
plt.title('Relationship of nutrients with temperature')
plt.show()

# Phosphates
sns.boxplot(x='Temp', y='Fosfatos_mg/L', data=Nutrientes_data)
plt.xlabel('Phosohates (mg/L)')
plt.ylabel('Temperatura (¬∞)')
plt.title('Relationship of nutrients with temperature')
plt.show()


## Linear regresion and least squares (OLS) regression¬¥
# Import library and read data with pandas 
# Clorophile a 
import matplotlib.pyplot as plt
from scipy import stats

x = Nutrientes_df['Clorofila a (mg/m3)']
y = Nutrientes_df['Fosfatos_mg/L']

plt.scatter(x, y, label='original data')

# Add labels and title
plt.xlabel('Cl a(%)', fontsize = 12, )
plt.ylabel('Phosphates ($mg/L$)', fontsize = 12)

# Calculate the linear regression line
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)

# Plot linear regression 

plt.plot(x, intercept + slope*x, 'r', label='fitted line')

# set the figure size
plt.gcf().set_size_inches(6, 4)

# save the plot as a PDF file paper format 
import os
output_dir = '../output_files'
os.makedirs(output_dir, exist_ok=True)
plt.savefig(os.path.join(output_dir, 'DIC_TA_pH.pdf'), dpi=300, bbox_inches='tight')


plt.show()

print('Slope:', slope)

print("r-squared:", r_value**2)
print("p_value:", p_value)
print("slope:", slope)
print("intercept:", intercept)


import statsmodels.api as sm
import numpy as np

# Define the independent and dependent variables
x = Nutrientes_df['Clorofila a (mg/m3)']
y = Nutrientes_df['Fosfatos_mg/L']



# Add a constant to include the intercept in the model
# This step is necessary; otherwise, the regression will be forced through the origin (intercept = 0)
x = sm.add_constant(x)

# Fit the Ordinary Least Squares (OLS) linear regression model
model = sm.OLS(y, x).fit()

# Display the model summary
print(model.summary())



print("\n=== MODEL INTERPRETATION ===\n")

# R-squared and fit quality
r2 = model.rsquared
fit_quality = (
    "‚úîÔ∏è Good model fit: Explains most of the variance." if r2 >= 0.7 else
    "‚ö†Ô∏è Moderate model fit: Explains part of the variance." if r2 >= 0.4 else
    "‚ùå Weak model fit: Explains little variance. Review your model."
)
print(f"R¬≤ = {r2:.3f}\n{fit_quality}")

# Coefficients and p-values
results = model.summary2().tables[1]
slope_var = results.index.drop('const')[0]  # Assuming one predictor

print("\nCoefficients:")
for var, row in results.iterrows():
    coef, pval = row['Coef.'], row['P>|t|']
    significance = "‚úîÔ∏è Significant (p < 0.05)" if pval < 0.05 else "‚ö†Ô∏è Not significant (p ‚â• 0.05)"
    print(f"- {var}: Coef = {coef:.4f}, p = {pval:.4f} ‚Üí {significance}")

# Slope interpretation
slope_coef, slope_pval = results.loc[slope_var, ['Coef.', 'P>|t|']]
print(f"\nSlope ({slope_var}): {slope_coef:.4f}, p = {slope_pval:.4f} ‚Üí "
      f"{'‚úîÔ∏è Significant' if slope_pval < 0.05 else '‚ö†Ô∏è Not significant'}")

# Standard Error
print(f"\nStandard Error of the model: {np.sqrt(model.scale):.4f}")


## PCA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Select variables for PCA
selected_vars = ['Clorofila a (mg/m3)', 'Nitritos_mg/L', 'Nitratos_mg/L', 
                 'Amonio_mg/L', 'Fosfatos_mg/L', 'Oxigeno_porcentaje', 
                 'Temp', 'Prof']

# Drop missing values and scale the data
X = Nutrientes_data[selected_vars].dropna()
X_scaled = StandardScaler().fit_transform(X)

def perform_adequacy_tests(data, selected_columns):
    """
    Perform Bartlett's test and KMO test for factor analysis.

    Parameters:
        data (pd.DataFrame): The input dataset.
        selected_columns (list): List of column names to include in the analysis.

    Returns:
        dict: Results of Bartlett's test and KMO test.
    """
    from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity, calculate_kmo

# Select numeric data and drop missing values
    numeric_values = data[selected_columns].dropna().select_dtypes(include=['float64', 'int64']).values

# Perform Bartlett's test
    chi_square, p_value = calculate_bartlett_sphericity(numeric_values)
    print(f"Bartlett's Test: p-value = {p_value:.4f}, chi-square = {chi_square:.4f}")

  # Perform KMO test
    _, kmo_model = calculate_kmo(numeric_values)
    print(f"KMO Value: {kmo_model:.1f}")

   # üìù Print interpretation of KMO value
    if kmo_model > 0.8:
        print("‚úÖ Suitability: Excellent üåü")
    elif 0.7 <= kmo_model <= 0.79:
        print("‚úÖ Suitability: Acceptable üëç")
    elif 0.6 <= kmo_model <= 0.69:
        print("‚ö†Ô∏è Suitability: Mediocre ü§î")
    else:
        print("‚ùå Suitability: Poor üö´")

    print("‚ÑπÔ∏è Interpretation: A KMO value above 0.6 is considered acceptable for factor analysis.")

   # üîÑ Return results
    return {"bartlett": {"chi_square": chi_square, "p_value": p_value}, "kmo": kmo_model}

# Select the variables for analysis
# Note: Ensure that the column names match those in your dataset
selected_vars = ['Clorofila a (mg/m3)', 'Nitritos_mg/L', 'Nitratos_mg/L', 
                 'Amonio_mg/L', 'Fosfatos_mg/L', 'Oxigeno_porcentaje', 
                 'Temp', 'Prof']

# Perform the adequacy tests
results = perform_adequacy_tests(Nutrientes_data, selected_vars)

# Es viable para PCA
# Perform PCA
pca = PCA()
principal_components = pca.fit_transform(X_scaled)
explained_variance = pca.explained_variance_ratio_
eigenvalues = pca.explained_variance_

# Scree plot
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o')
plt.axhline(y=1, color='red', linestyle='--', label='Kaiser Criterion')
plt.title('Scree Plot - PCA')
plt.xlabel('Principal Component')
plt.ylabel('Eigenvalue')
plt.legend()
plt.grid(True)
plt.show()

# Biplot function
def biplot(scores, coeff, labels=None):
    xs = scores[:, 0]
    ys = scores[:, 1]
    plt.figure(figsize=(8, 6))
    plt.scatter(xs, ys, alpha=0.5)
    for i in range(coeff.shape[0]):
        plt.arrow(0, 0, coeff[i, 0]*2, coeff[i, 1]*2, 
                  color='r', alpha=0.5)
        if labels is None:
            plt.text(coeff[i, 0]*2.2, coeff[i, 1]*2.2, f"Var{i+1}", color='g')
        else:
            plt.text(coeff[i, 0]*2.2, coeff[i, 1]*2.2, labels[i], color='g')
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.title("Biplot")
    plt.grid()
    plt.show()

# Display biplot for first two principal components
biplot(principal_components, pca.components_.T, labels=selected_vars)

# Include details on PCA results plot
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import colormaps
from matplotlib.patheffects import withStroke
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from typing import Optional, List, Tuple, Union # For type hinting

def plot_pca_biplot(
    df: pd.DataFrame,
    variables: List[str],
    group_col: Optional[str] = None,
    label_col: Optional[str] = None,
    scale_arrows: float = 2.5,
    figsize: Tuple[int, int] = (10, 10),
    title: str = "PCA Biplot",
    save_path: Optional[str] = None,
    point_size: int = 60,
    point_alpha: float = 0.8,
    arrow_color: str = 'black',
    arrow_linewidth: float = 2.0,
    arrow_alpha: float = 0.85,
    text_label_fontsize: float = 6.5,
    text_label_alpha: float = 0.6,
    var_label_fontsize: int = 12,
    var_label_color: str = 'green',
) -> None:
    """
    Generates a PCA biplot visualizing principal components scores and loadings.

    Returns:
        None: Displays or saves the Matplotlib plot.
    """
    # 1. Data Preparation
    cols_to_use = variables + [col for col in [group_col, label_col] if col]
    df_filtered = df.dropna(subset=cols_to_use).copy() # Use .copy() to avoid SettingWithCopyWarning

    if df_filtered.empty:
        print("Warning: DataFrame is empty after dropping NaNs. Cannot generate plot.")
        return

    X = df_filtered[variables]
    X_scaled = StandardScaler().fit_transform(X)

    # 2. PCA Calculation
    pca = PCA(n_components=2)
    scores = pca.fit_transform(X_scaled) # PC scores for each data point
    loadings = pca.components_.T         # Loadings for each variable

    # 3. Group and Label Information
    groups = df_filtered[group_col] if group_col else None
    labels = df_filtered[label_col] if label_col else None
    unique_groups = sorted(groups.unique()) if groups is not None else [None] # Handle None case for looping
    
    # Prepare colors only if grouping is needed
    colors = {}
    if groups is not None and len(unique_groups) > 0:
       num_groups = len(unique_groups)
       cmap = colormaps.get_cmap('viridis').resampled(num_groups)
       colors = {group: cmap(i) for i, group in enumerate(unique_groups)}
    else:
        # Set a default color if no grouping or only one group (which might be None)
        default_color = 'blue' 

    # 4. Plotting
    fig, ax = plt.subplots(figsize=figsize)
    ax.axhline(0, color='lightgray', lw=1, zorder=1)
    ax.axvline(0, color='lightgray', lw=1, zorder=1)

    # Plot Scores (Data Points)
    if groups is not None:
        for group in unique_groups:
            idx = (groups == group).values
            ax.scatter(scores[idx, 0], scores[idx, 1],
                       label=str(group), # Ensure group name is string for label
                       s=point_size, alpha=point_alpha,
                       edgecolor='white', linewidth=0.6,
                       color=colors[group], zorder=2)
        ax.legend(title=group_col, fontsize=10, title_fontsize=11)
    else:
        # Plot all points with default color if no groups
        ax.scatter(scores[:, 0], scores[:, 1], s=point_size, alpha=point_alpha,
                   color=default_color, edgecolor='white', linewidth=0.6, zorder=2)

    # Plot Point Labels (if specified)
    if labels is not None:
        # Iterate using index to ensure alignment with scores
        for i, txt in enumerate(labels):
             ax.text(scores[i, 0], scores[i, 1], txt,
                     fontsize=text_label_fontsize, alpha=text_label_alpha, zorder=3)

    # Plot Loadings (Variable Arrows)
    for i, var in enumerate(variables):
        arrow_x = loadings[i, 0] * scale_arrows
        arrow_y = loadings[i, 1] * scale_arrows
        ax.arrow(0, 0, arrow_x, arrow_y,
                 color=arrow_color, linewidth=arrow_linewidth, alpha=arrow_alpha,
                 head_width=0.1, head_length=0.12, length_includes_head=True, zorder=4)
        ax.text(arrow_x * 1.1, arrow_y * 1.1, var,
                fontsize=var_label_fontsize, ha='center', va='center', color=var_label_color,
                path_effects=[withStroke(linewidth=3, foreground='white')], zorder=5)

    # 5. Plot Customization & Finalization
    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=14, weight='bold')
    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=14, weight='bold')
    ax.set_title(title, fontsize=16, weight='bold')
    ax.set_aspect('equal') # Ensure aspect ratio is equal for PCA interpretability

    # Set reasonable limits based on scores, adding a margin
    margin_factor = 0.1 # Percentage margin
    xlim_min, xlim_max = scores[:, 0].min(), scores[:, 0].max()
    ylim_min, ylim_max = scores[:, 1].min(), scores[:, 1].max()
    x_margin = (xlim_max - xlim_min) * margin_factor
    y_margin = (ylim_max - ylim_min) * margin_factor
    ax.set_xlim(xlim_min - x_margin, xlim_max + x_margin)
    ax.set_ylim(ylim_min - y_margin, ylim_max + y_margin)

    plt.tight_layout()

    # 6. Save or Show
    if save_path:
        # Determine DPI based on file extension for common raster formats
        is_raster = save_path.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff'))
        dpi = 600 if is_raster else None # Use 300 dpi for raster, None for vector (svg, pdf)
        try:
            plt.savefig(save_path, dpi=dpi, bbox_inches='tight')
            print(f"Plot saved to {save_path}")
        except Exception as e:
            print(f"Error saving plot: {e}")
    
    plt.show()

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from matplotlib import colormaps

def preprocess_data(df, variables):
    """
    Standardize selected variables and return clean DataFrame.
    """
    df_clean = df.dropna(subset=variables)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_clean[variables])
    return df_clean, X_scaled

def perform_hierarchical_clustering(X_scaled, method='ward', n_clusters=3):
    """
    Perform hierarchical clustering and return cluster labels.
    """
    linkage_matrix = linkage(X_scaled, method=method)
    cluster_labels = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')
    return linkage_matrix, cluster_labels

def plot_dendrogram(linkage_matrix, labels=None, n_clusters=3):
    """
    Plot a dendrogram from the hierarchical clustering with sample labels.
    Annotate the plot with the number of clusters.
    """
    # Generate cluster labels
    cluster_labels = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')

    plt.figure(figsize=(10, 5))
    dendrogram(
        linkage_matrix,
        labels=labels,
        above_threshold_color='gray'  # Default color for links above the threshold
    )
    plt.title(f'Hierarchical Clustering Dendrogram\n(Number of Clusters: {n_clusters})')
    plt.xlabel('Sample Labels')
    plt.ylabel('Distance')
    plt.tight_layout()
    plt.show()



# Select variables for clustering
selected_vars = ['Clorofila a (mg/m3)', 'Nitritos_mg/L', 'Nitratos_mg/L', 'Amonio_mg/L', 'Fosfatos_mg/L', 'Oxigeno_porcentaje', 'Temp', 'Prof']

# Preprocess the data;  Drop rows with missing values in selected variables
# Standardize the selected variables using StandardScaler
df_clean, X_scaled = preprocess_data(Nutrientes_data, selected_vars)

# Perform hierarchical clustering sing thue 'ward' method 
# The number of clusters to be 3,  You can adjust the number of clusters as needed
linkage_matrix, clusters = perform_hierarchical_clustering(X_scaled, n_clusters=10)
 
# Add cluster labels to the DataFrame
df_clean['cluster'] = clusters

# Plot dendrogram using sample labels 
plot_dendrogram(linkage_matrix, labels=df_clean['cluster'].values)



## A relationship was observed between nutrients, particularly chlorophyll a and phosphates. Phosphates are an essential nutrient that acts as a limiting factor for the growth of phytoplankton, which produces chlorophyll. According to the Biplot, nitrites and nitrates are related to temperature. The reactions that convert nitrate to nitrite (or vice versa) are catalyzed by microorganisms that are activated or inactivated depending on the temperature.

# Rererences
# Herrera-Silveira J. A., Com√≠n S. F. A., and Capurro F. L. 2005. The uses and abuses of the coastal zone in the Yucat√°n Peninsula. Autonomous University of Campeche. Chapter 1. 26. 387-396
# Herrera-Silveira, J. A., Cort√©s Bal√°n, T. O., Ram√≠rez-Ram√≠rez, J., and I. Osorio (2015). Monitoring the trophic condition of the water column in the coastal environments of the Costa Occidental de Isla Mujeres National Park, Punta Canc√∫n, and Punta Nizuc: Second Stage. Research and Advanced Studies Center-M√©rida Project. SNIBCONABIO Final Report, Project No. GQ002, Mexico City.
# Hern√°ndez-Terrones L. M., Null A. K., Ortega-Camacho D. y Paytan A. (2015) Water quality assessment in the Mexican Caribbean: Impacts on the coastal ecosystem. Continental Shelf Research 102. 62‚Äì72.